{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TddHqVqwVjhY",
        "outputId": "46cdc54d-083e-4f45-94f7-41abc634c9f7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "YOLOv5  2025-12-9 Python-3.10.4 torch-1.13.1+cpu CPU\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Setup complete  (16 CPUs, 15.7 GB RAM, 59.1/244.1 GB disk)\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/ultralytics/yolov5  # clone\n",
        "%cd yolov5\n",
        "%pip install -qr requirements.txt  # install\n",
        "\n",
        "import torch\n",
        "\n",
        "import utils\n",
        "\n",
        "display = utils.notebook_init()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zKIifGV4VmF-",
        "outputId": "fc5649a2-56c4-4fca-8d7d-1e2e63d8f63c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "D:\\ambu-fire-ocv\\Ambulance-firetruck-detection-yolov5-main\\utils\\general.py:32: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
            "  import pkg_resources as pkg\n",
            "\u001b[34m\u001b[1mclassify\\predict: \u001b[0mweights=['yolov5s-cls.pt'], source=data/images, data=data\\coco128.yaml, imgsz=[224, 224], device=, view_img=False, save_txt=False, nosave=False, augment=False, visualize=False, update=False, project=runs\\predict-cls, name=exp, exist_ok=False, half=False, dnn=False, vid_stride=1\n",
            "YOLOv5  2025-12-9 Python-3.10.4 torch-1.13.1+cpu CPU\n",
            "\n",
            "Fusing layers... \n",
            "Model summary: 117 layers, 5447688 parameters, 0 gradients, 11.4 GFLOPs\n",
            "image 1/2 D:\\ambu-fire-ocv\\Ambulance-firetruck-detection-yolov5-main\\data\\images\\bus.jpg: 224x224 minibus 0.39, police van 0.24, amphibious vehicle 0.05, recreational vehicle 0.04, trolleybus 0.03, 106.7ms\n",
            "image 2/2 D:\\ambu-fire-ocv\\Ambulance-firetruck-detection-yolov5-main\\data\\images\\zidane.jpg: 224x224 suit 0.38, bow tie 0.19, bridegroom 0.18, rugby ball 0.04, stage 0.02, 110.4ms\n",
            "Speed: 2.6ms pre-process, 108.5ms inference, 2.3ms NMS per image at shape (1, 3, 224, 224)\n",
            "Results saved to \u001b[1mruns\\predict-cls\\exp4\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!python classify/predict.py --weights yolov5s-cls.pt --img 224 --source data/images\n",
        "# display.Image(filename='runs/predict-cls/exp/zidane.jpg', width=600)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-0JXxlJxWDbz",
        "outputId": "0b22c038-b3b3-45b7-fd95-76cdb2222db6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<3>WSL (449 - Relay) ERROR: CreateProcessCommon:735: execvpe(/bin/bash) failed: No such file or directory\n"
          ]
        }
      ],
      "source": [
        "# Download Imagenet val (6.3G, 40000 images)\n",
        "!bash data/scripts/get_imagenet.sh --val"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MD5IMju3XQIr",
        "outputId": "fdf5cb6b-d5d4-456d-d834-221237145472"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "D:\\ambu-fire-ocv\\Ambulance-firetruck-detection-yolov5-main\\utils\\general.py:32: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
            "  import pkg_resources as pkg\n",
            "\u001b[34m\u001b[1mclassify\\val: \u001b[0mdata=../datasets/imagenet, weights=['yolov5s-cls.pt'], batch_size=128, imgsz=224, device=, workers=8, verbose=True, project=runs\\val-cls, name=exp, exist_ok=False, half=True, dnn=False\n",
            "YOLOv5  2025-12-9 Python-3.10.4 torch-1.13.1+cpu CPU\n",
            "\n",
            "Fusing layers... \n",
            "Model summary: 117 layers, 5447688 parameters, 0 gradients, 11.4 GFLOPs\n",
            "Traceback (most recent call last):\n",
            "  File \"d:\\ambu-fire-ocv\\Ambulance-firetruck-detection-yolov5-main\\classify\\val.py\", line 178, in <module>\n",
            "    main(opt)\n",
            "  File \"d:\\ambu-fire-ocv\\Ambulance-firetruck-detection-yolov5-main\\classify\\val.py\", line 173, in main\n",
            "    run(**vars(opt))\n",
            "  File \"c:\\Users\\Abhishek\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\autograd\\grad_mode.py\", line 27, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "  File \"d:\\ambu-fire-ocv\\Ambulance-firetruck-detection-yolov5-main\\classify\\val.py\", line 101, in run\n",
            "    dataloader = create_classification_dataloader(\n",
            "  File \"D:\\ambu-fire-ocv\\Ambulance-firetruck-detection-yolov5-main\\utils\\dataloaders.py\", line 1363, in create_classification_dataloader\n",
            "    dataset = ClassificationDataset(root=path, imgsz=imgsz, augment=augment, cache=cache)\n",
            "  File \"D:\\ambu-fire-ocv\\Ambulance-firetruck-detection-yolov5-main\\utils\\dataloaders.py\", line 1332, in __init__\n",
            "    super().__init__(root=root)\n",
            "  File \"c:\\Users\\Abhishek\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\datasets\\folder.py\", line 309, in __init__\n",
            "    super().__init__(\n",
            "  File \"c:\\Users\\Abhishek\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\datasets\\folder.py\", line 144, in __init__\n",
            "    classes, class_to_idx = self.find_classes(self.root)\n",
            "  File \"c:\\Users\\Abhishek\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\datasets\\folder.py\", line 218, in find_classes\n",
            "    return find_classes(directory)\n",
            "  File \"c:\\Users\\Abhishek\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\datasets\\folder.py\", line 40, in find_classes\n",
            "    classes = sorted(entry.name for entry in os.scandir(directory) if entry.is_dir())\n",
            "FileNotFoundError: [WinError 3] The system cannot find the path specified: '..\\\\datasets\\\\imagenet\\\\val'\n"
          ]
        }
      ],
      "source": [
        "# Validate YOLOv5s on Imagenet val\n",
        "!python classify/val.py --weights yolov5s-cls.pt --data ../datasets/imagenet --img 224 --half"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bqqiSj19YvgH",
        "outputId": "2420d8cf-9079-4ae0-9e24-639c702cf6f8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/780.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[91mâ•¸\u001b[0m \u001b[32m778.2/780.9 kB\u001b[0m \u001b[31m28.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m780.9/780.9 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/1.3 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m65.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m comet_ml.init() is deprecated and will be removed soon. Please use comet_ml.login()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Please paste your Comet API key from https://www.comet.com/api/my/settings/\n",
            "(api key may not show as you type)\n",
            "Comet API key: Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Valid Comet API Key saved in /root/.comet.config (set COMET_CONFIG to change where it is saved).\n"
          ]
        }
      ],
      "source": [
        "# @title Select YOLOv5 ğŸš€ logger {run: 'auto'}\n",
        "logger = \"Comet\"  # @param ['Comet', 'ClearML', 'TensorBoard']\n",
        "\n",
        "if logger == \"Comet\":\n",
        "    %pip install -q comet_ml\n",
        "    import comet_ml\n",
        "\n",
        "    comet_ml.init()\n",
        "elif logger == \"ClearML\":\n",
        "    %pip install -q clearml\n",
        "    import clearml\n",
        "\n",
        "    clearml.browser_login()\n",
        "elif logger == \"TensorBoard\":\n",
        "    %load_ext tensorboard\n",
        "    %tensorboard --logdir runs/train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NronVlNIaW4s",
        "outputId": "3ac73fbe-d208-430b-aff5-df96e1d92334"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-12-10 03:59:05.887749: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1765339146.157618   57593 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1765339146.227806   57593 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1765339146.758953   57593 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1765339146.758992   57593 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1765339146.758996   57593 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1765339146.759002   57593 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "\u001b[34m\u001b[1mclassify/train: \u001b[0mmodel=yolov5s-cls.pt, data=imagenette160, epochs=5, batch_size=64, imgsz=224, nosave=False, cache=ram, device=, workers=8, project=runs/train-cls, name=exp, exist_ok=False, pretrained=True, optimizer=Adam, lr0=0.001, decay=5e-05, label_smoothing=0.1, cutoff=None, dropout=None, verbose=False, seed=0, local_rank=-1\n",
            "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 âœ…\n",
            "YOLOv5 ğŸš€ v7.0-450-g781b9d57 Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train-cls', view at http://localhost:6006/\n",
            "\n",
            "Dataset not found âš ï¸, missing path /content/datasets/imagenette160, attempting download...\n",
            "Downloading https://github.com/ultralytics/assets/releases/download/v0.0.0/imagenette160.zip to /content/datasets/imagenette160.zip...\n",
            "100% 103M/103M [00:02<00:00, 41.3MB/s] \n",
            "Unzipping /content/datasets/imagenette160.zip...\n",
            "Dataset download success âœ… (5.1s), saved to \u001b[1m/content/datasets/imagenette160\u001b[0m\n",
            "\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0m1 validation error for InitSchema\n",
            "size\n",
            "  Field required [type=missing, input_value={'scale': (0.08, 1.0), 'r...': 1.0, 'strict': False}, input_type=dict]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/missing\n",
            "Model summary: 149 layers, 4185290 parameters, 4185290 gradients, 10.5 GFLOPs\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m Adam(lr=0.001) with parameter groups 32 weight(decay=0.0), 33 weight(decay=5e-05), 33 bias\n",
            "/content/yolov5/classify/train.py:201: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = amp.GradScaler(enabled=cuda)\n",
            "Image sizes 224 train, 224 test\n",
            "Using 1 dataloader workers\n",
            "Logging results to \u001b[1mruns/train-cls/exp\u001b[0m\n",
            "Starting yolov5s-cls.pt training on imagenette160 dataset with 10 classes for 5 epochs...\n",
            "\n",
            "     Epoch   GPU_mem  train_loss    val_loss    top1_acc    top5_acc\n",
            "  0% 0/148 [00:00<?, ?it/s]/content/yolov5/classify/train.py:222: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast(enabled=cuda):  # stability issues when enabled\n",
            "       1/5     1.46G       0.822                          validating:   0% 0/31 [00:00<?, ?it/s]/content/yolov5/classify/val.py:111: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=device.type != \"cpu\"):\n",
            "       1/5     1.46G       0.822       0.762       0.913       0.992: 100% 148/148 [00:34<00:00,  4.30it/s]\n",
            "       2/5     1.76G       0.614         0.7       0.928       0.996: 100% 148/148 [00:34<00:00,  4.25it/s]\n",
            "       3/5     1.76G       0.549       0.639       0.955       0.998: 100% 148/148 [00:28<00:00,  5.22it/s]\n",
            "       4/5     1.76G       0.522       0.623       0.957       0.998: 100% 148/148 [00:26<00:00,  5.64it/s]\n",
            "       5/5     1.76G       0.515       0.618       0.962       0.998: 100% 148/148 [00:26<00:00,  5.66it/s]\n",
            "\n",
            "Training complete (0.042 hours)\n",
            "Results saved to \u001b[1mruns/train-cls/exp\u001b[0m\n",
            "Predict:         python classify/predict.py --weights runs/train-cls/exp/weights/best.pt --source im.jpg\n",
            "Validate:        python classify/val.py --weights runs/train-cls/exp/weights/best.pt --data /content/datasets/imagenette160\n",
            "Export:          python export.py --weights runs/train-cls/exp/weights/best.pt --include onnx\n",
            "PyTorch Hub:     model = torch.hub.load('ultralytics/yolov5', 'custom', 'runs/train-cls/exp/weights/best.pt')\n",
            "Visualize:       https://netron.app\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Train YOLOv5s Classification on Imagenette160 for 3 epochs\n",
        "!python classify/train.py --model yolov5s-cls.pt --data imagenette160 --epochs 5 --img 224 --cache"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hhWzwPW5biSb",
        "outputId": "f81f6436-556b-4b54-cfbc-49d5d0074569"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading: \"https://github.com/ultralytics/yolov5/zipball/master\" to /root/.cache/torch/hub/master.zip\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "YOLOv5 ğŸš€ v7.0-450-g781b9d57 Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\n",
            "Downloading https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5s.pt to yolov5s.pt...\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14.1M/14.1M [00:00<00:00, 178MB/s]\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients, 16.4 GFLOPs\n",
            "Adding AutoShape... \n",
            "/root/.cache/torch/hub/ultralytics_yolov5_master/models/common.py:898: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast(autocast):\n",
            "image 1/1: 720x1280 2 persons, 1 tie, 1 cell phone\n",
            "Speed: 733.7ms pre-process, 100.4ms inference, 270.4ms NMS per image at shape (1, 3, 384, 640)\n"
          ]
        }
      ],
      "source": [
        "# YOLOv5 PyTorch HUB Inference (DetectionModels only)\n",
        "\n",
        "model = torch.hub.load(\n",
        "    \"ultralytics/yolov5\", \"yolov5s\", force_reload=True, trust_repo=True\n",
        ")  # or yolov5n - yolov5x6 or custom\n",
        "im = \"https://ultralytics.com/images/zidane.jpg\"  # file, Path, PIL.Image, OpenCV, nparray, list\n",
        "results = model(im)  # inference\n",
        "results.print()  # or .show(), .save(), .crop(), .pandas(), etc."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
